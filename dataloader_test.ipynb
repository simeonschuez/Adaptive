{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "\n",
    "from data_utils import get_karpathy_split, refcoco_splits\n",
    "from data_loader import get_caption_loader, COCOCaptionDataset, get_reg_loader\n",
    "\n",
    "from build_vocab import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/simeon/Dokumente/Code/Uni/Repos/Adaptive/nlg-eval')\n",
    "from nlgeval import NLGEval\n",
    "nlgeval = NLGEval(no_skipthoughts=True, no_glove=True)  # loads the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size=224\n",
    "image_dir='/home/simeon/Dokumente/Code/Data/COCO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coco_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_df = get_karpathy_split(splits_path='/home/simeon/Dokumente/Code/Data/COCO/splits/karpathy/caption_datasets/', caps_path='/home/simeon/Dokumente/Code/Data/COCO/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((crop_size, crop_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = caps_df.loc[caps_df.split == 'restval'].iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_caption_loader(\n",
    "        decoding_level='word', \n",
    "        split=['val'],\n",
    "        data_df=caps_df, \n",
    "        image_dir=image_dir, \n",
    "        vocab=vocab,\n",
    "        transform=transform, \n",
    "        batch_size=20, \n",
    "        shuffle=False,\n",
    "        num_workers=2, \n",
    "        drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<start> a bicycle is chained up to a pole at a train station <end> <pad> <pad>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (images, captions, lengths, _, _) in enumerate(loader):    \n",
    "    if i > 2:\n",
    "        break\n",
    "    print(i)\n",
    "    \n",
    "idx = [i.item() for i in captions[2]]\n",
    "' '.join([vocab.idx2word[i] for i in idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "caps_df.loc[caps_df.image_id == 318556].caption.map(str.strip).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for i, (images, _, _, image_ids, _) in enumerate(loader):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # Build caption based on Vocabulary and the '<end>' token\n",
    "    for image_idx in range(images.size()[0]):\n",
    "\n",
    "        img_id = int(image_ids[image_idx])\n",
    "\n",
    "        refs = caps_df.loc[caps_df.image_id == img_id].caption.to_list()\n",
    "        references.append(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/refcoco_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = refcoco_splits('/home/simeon/Dokumente/Code/Data/RefCOCO/refcoco/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_reg_loader(\n",
    "        decoding_level='word', \n",
    "        split=['val'],\n",
    "        data_df=ref_df.groupby('ann_id').agg('first').reset_index(), \n",
    "        image_dir=image_dir, \n",
    "        vocab=vocab,\n",
    "        transform=transform, \n",
    "        batch_size=20, \n",
    "        shuffle=False,\n",
    "        num_workers=2, \n",
    "        drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for i, (images, targets, positions, lengths, ann_ids, filenames) in enumerate(loader):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # Build caption based on Vocabulary and the '<end>' token\n",
    "    for ann_idx in range(images.size()[0]):\n",
    "\n",
    "        ann_id = int(ann_ids[ann_idx])\n",
    "\n",
    "        refs = ref_df.loc[ref_df.ann_id == ann_id].caption.to_list()\n",
    "        references.append(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, (images, captions, positions, lengths, ann_ids, filenames) in enumerate(loader):    \n",
    "    if i > 2:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> bird closest to camera <end> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [i.item() for i in captions[2]]\n",
    "' '.join([vocab.idx2word[i] for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_reg import Encoder2Decoder\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder2Decoder(256, len(vocab), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = AttentiveCNN(256, 512)\n",
    "# encoder.affine_b = nn.Linear(2048+7, 256)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Last conv layer feature map\n",
    "A = encoder.resnet_conv(images)\n",
    "\n",
    "# a^g, average pooling feature map\n",
    "# global image feature vector\n",
    "a_g = encoder.avgpool(A)\n",
    "a_g = a_g.view(a_g.size(0), -1)\n",
    "\n",
    "# V = [v_1, v_2, ..., v_49]\n",
    "# spatial image feature vector\n",
    "V = A.view(A.size(0), A.size(1), -1).transpose(1,2)\n",
    "V = F.relu(encoder.affine_a(encoder.dropout(V)))\n",
    "\n",
    "# append location features to global image feature vector\n",
    "a_g_loc = torch.cat(\n",
    "    (encoder.dropout(a_g),\n",
    "    positions),\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "v_g = F.relu(encoder.affine_b(a_g_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2465,  493, 2886,  454,  239, 1564,  454,  981, 2209, 2717,  565, 1634,\n",
       "          1833, 1409,   18, 2105,  507,  410, 2465, 2465],\n",
       "         [1835, 1095, 2657, 2394, 2062,  405, 2510,  341,  729,  931, 1095, 1634,\n",
       "          1521, 2465, 2465, 1255, 2465,  843, 2165, 2165],\n",
       "         [2209,  701, 1634, 2465,  639, 2324, 2460, 2465, 1897, 2465, 2653,  870,\n",
       "           707, 2209,  933, 1392, 1598, 1095, 2394, 1203],\n",
       "         [2465, 2465, 2796, 2209, 2046, 2445,  275, 1952, 2465,  791, 1952,  289,\n",
       "           701, 2465,  454,  512,  512, 2417,  830, 2465],\n",
       "         [2465, 1634, 2165, 2031, 2698, 2165, 2165,  788, 2465, 2465, 1049, 1897,\n",
       "           922, 2165, 2465, 2465, 1049, 1416,  701, 2962],\n",
       "         [1672, 1318,  311, 2465, 2209, 1891, 2465,  757, 1897, 1049, 1049, 1049,\n",
       "          1634, 2465, 2465, 1318,  488,  208,  134, 1049],\n",
       "         [1255, 1952, 2465,  512, 1255, 2110, 1489, 2465,  493,  454,  843,  729,\n",
       "          2153,  841,  454,  454, 2465, 2465, 2465, 2796],\n",
       "         [2465,  507, 1857, 2632,  702, 1907, 1522, 2465, 2465, 2836, 2460, 1835,\n",
       "          2465, 2465, 2465,   23, 1862,  905,  507, 2465],\n",
       "         [1511, 1272, 2116,  512,  702, 2465, 2465, 2314, 1634,  916, 2465,  498,\n",
       "          2465, 1634,  843, 1489, 2394,  498, 1634,  152],\n",
       "         [ 337, 1193, 1600,  405, 1049, 1880,  639, 2733,  841, 2105, 1634, 1095,\n",
       "          1588, 1958, 2095, 2796, 2896, 2139, 2702, 1318],\n",
       "         [ 454,   35,  820,  702, 2419,  561, 1255, 2465,  702,  981, 1857, 1470,\n",
       "          2165, 2465, 1236, 1521,  405, 1634, 2711, 1470],\n",
       "         [2711, 1906, 1049, 1907,  208,  429, 1539, 1255, 1672,  454, 1634,  232,\n",
       "          2450,  830, 1489,  841, 2153, 2465,  454, 1049],\n",
       "         [ 108,  702, 2095, 1899,  232, 1255, 1553, 1255, 2465,  590, 2417, 2564,\n",
       "           152,  843, 2175, 2896,  421, 1991, 1345, 1049],\n",
       "         [2698,  204, 1291,  410, 2465, 2782,  454, 2417, 2209, 2515, 2698, 2465,\n",
       "           507, 2024, 2465,  454, 2782, 2465, 1672, 2465],\n",
       "         [ 405,  870, 2465, 2394, 2895,  405, 1318, 1774, 2465, 2465,  405,  639,\n",
       "          1862, 1666, 2465, 2465,  870,  870, 2592, 2970],\n",
       "         [2581,  405, 2372, 2548, 1318, 2209, 1931,  134, 1356, 2157, 2970, 2465,\n",
       "           454, 2938,  692, 2165, 2653,  702, 2392, 2153],\n",
       "         [ 704, 2465, 2916,  870, 2417, 2175,  843, 1852,  843,  151, 2153, 2165,\n",
       "           454,  701, 2007, 2165,  454,   60,  843,  507],\n",
       "         [ 108, 1015,  454, 1588, 2465,  108,  702,  855,  454, 1108, 2465, 2465,\n",
       "          2465, 1880, 1317,  362, 1862, 1049, 2007, 1147],\n",
       "         [1318, 2165, 2465, 2487,  533,  507, 1489,  729, 1176, 1223,  268, 2465,\n",
       "          1901, 2392, 2153, 1835, 2465,  577, 1049, 2465],\n",
       "         [1979, 2487, 2817, 1049,  912,   23,  204, 2359,  773,  822, 2465,  454,\n",
       "          1299,  204,  981,  204, 2465, 2165, 2314, 1255]]),\n",
       " tensor([[[1.0613e-02, 8.7243e-04, 1.4078e-03,  ..., 1.8519e-02,\n",
       "           2.1897e-03, 9.5794e-03],\n",
       "          [9.2414e-03, 3.6580e-03, 1.0344e-01,  ..., 2.1335e-02,\n",
       "           5.2876e-02, 5.7272e-02],\n",
       "          [1.1643e-02, 9.6017e-03, 5.0278e-03,  ..., 1.2879e-02,\n",
       "           1.1869e-01, 3.4815e-03],\n",
       "          ...,\n",
       "          [1.6346e-02, 1.9293e-03, 3.3664e-03,  ..., 7.3148e-03,\n",
       "           1.0826e-02, 3.6080e-03],\n",
       "          [1.4265e-03, 7.0985e-03, 9.7278e-03,  ..., 7.0089e-02,\n",
       "           6.2530e-03, 3.7407e-03],\n",
       "          [2.7084e-02, 1.0102e-01, 4.8768e-03,  ..., 1.3802e-03,\n",
       "           6.5083e-03, 1.5810e-01]],\n",
       " \n",
       "         [[1.4324e-03, 7.2371e-03, 3.2932e-02,  ..., 3.9079e-03,\n",
       "           7.0560e-04, 1.4368e-03],\n",
       "          [1.2245e-03, 4.3925e-02, 5.4400e-03,  ..., 1.4019e-02,\n",
       "           3.2466e-03, 5.1930e-03],\n",
       "          [1.1482e-03, 6.9643e-03, 1.1794e-03,  ..., 8.5751e-03,\n",
       "           1.9899e-03, 1.3613e-03],\n",
       "          ...,\n",
       "          [2.3910e-03, 8.9486e-04, 2.2185e-03,  ..., 1.1922e-02,\n",
       "           9.3212e-04, 1.0366e-03],\n",
       "          [8.1290e-03, 4.1463e-04, 5.0335e-03,  ..., 1.6571e-02,\n",
       "           1.0154e-03, 1.0244e-03],\n",
       "          [4.3922e-02, 4.5551e-02, 2.0150e-03,  ..., 9.3173e-03,\n",
       "           1.1469e-02, 3.9450e-03]],\n",
       " \n",
       "         [[3.6404e-02, 2.1209e-02, 1.6044e-02,  ..., 2.1107e-02,\n",
       "           2.4305e-02, 7.0030e-03],\n",
       "          [1.9118e-01, 1.5834e-02, 1.1227e-03,  ..., 3.8309e-02,\n",
       "           1.8498e-03, 1.2718e-04],\n",
       "          [1.6513e-02, 5.6151e-03, 2.5309e-02,  ..., 1.5194e-02,\n",
       "           1.7905e-02, 7.9964e-03],\n",
       "          ...,\n",
       "          [4.7113e-02, 1.5339e-02, 6.7195e-03,  ..., 5.2744e-03,\n",
       "           4.0711e-03, 4.5072e-03],\n",
       "          [3.3009e-02, 1.9351e-03, 5.8410e-02,  ..., 1.8406e-03,\n",
       "           3.8721e-02, 3.9934e-02],\n",
       "          [3.6977e-02, 1.3374e-03, 1.3487e-02,  ..., 3.7810e-02,\n",
       "           6.5350e-03, 3.8430e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4.2399e-03, 4.3091e-03, 1.0576e-02,  ..., 1.4237e-01,\n",
       "           1.2910e-01, 3.2800e-03],\n",
       "          [1.1570e-02, 1.0475e-02, 1.4121e-02,  ..., 1.2145e-01,\n",
       "           6.3221e-02, 5.8141e-02],\n",
       "          [4.2876e-02, 1.3351e-02, 3.4479e-03,  ..., 2.1311e-03,\n",
       "           1.2964e-01, 4.8167e-03],\n",
       "          ...,\n",
       "          [1.0108e-03, 4.4948e-03, 2.7186e-02,  ..., 3.3110e-03,\n",
       "           1.1842e-01, 3.3256e-02],\n",
       "          [5.0784e-03, 1.4074e-03, 7.9018e-04,  ..., 8.8639e-03,\n",
       "           1.0022e-02, 1.2019e-02],\n",
       "          [3.1336e-03, 5.4935e-03, 1.0975e-02,  ..., 6.5259e-03,\n",
       "           4.8014e-02, 3.3478e-03]],\n",
       " \n",
       "         [[1.5459e-03, 2.1965e-03, 8.4529e-03,  ..., 3.2620e-03,\n",
       "           1.7594e-02, 6.3780e-03],\n",
       "          [6.8266e-04, 3.2065e-03, 2.1621e-03,  ..., 8.1148e-03,\n",
       "           4.1466e-02, 7.4995e-04],\n",
       "          [1.6831e-03, 1.9821e-03, 2.5143e-03,  ..., 4.4925e-03,\n",
       "           4.0468e-02, 5.6870e-02],\n",
       "          ...,\n",
       "          [1.5540e-02, 2.3626e-02, 5.5014e-04,  ..., 1.7706e-03,\n",
       "           2.7180e-03, 1.0355e-03],\n",
       "          [9.1986e-03, 5.8758e-03, 2.8949e-03,  ..., 2.3937e-02,\n",
       "           6.2759e-03, 7.4449e-03],\n",
       "          [1.0204e-02, 1.5841e-03, 2.8260e-02,  ..., 2.6013e-03,\n",
       "           8.3738e-03, 1.0605e-02]],\n",
       " \n",
       "         [[3.4957e-03, 1.6965e-02, 3.7824e-02,  ..., 1.1213e-03,\n",
       "           2.0846e-02, 2.8084e-02],\n",
       "          [7.7642e-02, 1.6503e-02, 1.2046e-03,  ..., 2.5359e-02,\n",
       "           9.2029e-04, 1.0936e-03],\n",
       "          [8.9588e-03, 1.1752e-03, 4.4781e-02,  ..., 1.8175e-03,\n",
       "           1.1250e-01, 2.1674e-03],\n",
       "          ...,\n",
       "          [6.3307e-03, 1.7932e-03, 5.2236e-02,  ..., 2.9866e-02,\n",
       "           4.5304e-03, 4.2832e-02],\n",
       "          [5.9376e-02, 3.1193e-02, 2.6277e-03,  ..., 1.0448e-03,\n",
       "           7.9022e-02, 1.2318e-02],\n",
       "          [5.6358e-03, 5.9509e-04, 8.1739e-03,  ..., 1.4942e-03,\n",
       "           3.1952e-02, 2.9738e-03]]], grad_fn=<CatBackward>),\n",
       " tensor([[[0.0388],\n",
       "          [0.0187],\n",
       "          [0.0400],\n",
       "          [0.0102],\n",
       "          [0.0088],\n",
       "          [0.0089],\n",
       "          [0.0049],\n",
       "          [0.0340],\n",
       "          [0.0063],\n",
       "          [0.0071],\n",
       "          [0.0100],\n",
       "          [0.0056],\n",
       "          [0.0129],\n",
       "          [0.0046],\n",
       "          [0.0106],\n",
       "          [0.0130],\n",
       "          [0.0057],\n",
       "          [0.0129],\n",
       "          [0.0270],\n",
       "          [0.0073]],\n",
       " \n",
       "         [[0.0096],\n",
       "          [0.0108],\n",
       "          [0.0063],\n",
       "          [0.0071],\n",
       "          [0.0086],\n",
       "          [0.0134],\n",
       "          [0.0034],\n",
       "          [0.0118],\n",
       "          [0.0051],\n",
       "          [0.0149],\n",
       "          [0.0148],\n",
       "          [0.0047],\n",
       "          [0.0040],\n",
       "          [0.0067],\n",
       "          [0.0048],\n",
       "          [0.0099],\n",
       "          [0.0098],\n",
       "          [0.0031],\n",
       "          [0.0019],\n",
       "          [0.0117]],\n",
       " \n",
       "         [[0.0201],\n",
       "          [0.0056],\n",
       "          [0.0105],\n",
       "          [0.0069],\n",
       "          [0.0171],\n",
       "          [0.0069],\n",
       "          [0.0143],\n",
       "          [0.0067],\n",
       "          [0.0106],\n",
       "          [0.0114],\n",
       "          [0.0100],\n",
       "          [0.0037],\n",
       "          [0.0055],\n",
       "          [0.0290],\n",
       "          [0.0233],\n",
       "          [0.0332],\n",
       "          [0.0286],\n",
       "          [0.0338],\n",
       "          [0.0156],\n",
       "          [0.0084]],\n",
       " \n",
       "         [[0.0309],\n",
       "          [0.0234],\n",
       "          [0.0072],\n",
       "          [0.0050],\n",
       "          [0.0233],\n",
       "          [0.0163],\n",
       "          [0.0133],\n",
       "          [0.0076],\n",
       "          [0.0194],\n",
       "          [0.0246],\n",
       "          [0.0080],\n",
       "          [0.0129],\n",
       "          [0.0269],\n",
       "          [0.0089],\n",
       "          [0.0062],\n",
       "          [0.0346],\n",
       "          [0.0368],\n",
       "          [0.0112],\n",
       "          [0.0181],\n",
       "          [0.0146]],\n",
       " \n",
       "         [[0.0084],\n",
       "          [0.0043],\n",
       "          [0.0050],\n",
       "          [0.0015],\n",
       "          [0.0159],\n",
       "          [0.0058],\n",
       "          [0.0078],\n",
       "          [0.0053],\n",
       "          [0.0067],\n",
       "          [0.0091],\n",
       "          [0.0012],\n",
       "          [0.0114],\n",
       "          [0.0164],\n",
       "          [0.0136],\n",
       "          [0.0048],\n",
       "          [0.0033],\n",
       "          [0.0030],\n",
       "          [0.0043],\n",
       "          [0.0103],\n",
       "          [0.0019]],\n",
       " \n",
       "         [[0.0188],\n",
       "          [0.0123],\n",
       "          [0.0337],\n",
       "          [0.0099],\n",
       "          [0.0383],\n",
       "          [0.0070],\n",
       "          [0.0055],\n",
       "          [0.0081],\n",
       "          [0.0124],\n",
       "          [0.0219],\n",
       "          [0.0145],\n",
       "          [0.0138],\n",
       "          [0.0131],\n",
       "          [0.0218],\n",
       "          [0.0052],\n",
       "          [0.0351],\n",
       "          [0.0058],\n",
       "          [0.0042],\n",
       "          [0.0102],\n",
       "          [0.0341]],\n",
       " \n",
       "         [[0.0085],\n",
       "          [0.0016],\n",
       "          [0.0234],\n",
       "          [0.0085],\n",
       "          [0.0258],\n",
       "          [0.0404],\n",
       "          [0.0053],\n",
       "          [0.0195],\n",
       "          [0.0108],\n",
       "          [0.0061],\n",
       "          [0.0024],\n",
       "          [0.0029],\n",
       "          [0.0522],\n",
       "          [0.0138],\n",
       "          [0.0160],\n",
       "          [0.0134],\n",
       "          [0.0223],\n",
       "          [0.0382],\n",
       "          [0.0168],\n",
       "          [0.0037]],\n",
       " \n",
       "         [[0.0057],\n",
       "          [0.0022],\n",
       "          [0.0091],\n",
       "          [0.0061],\n",
       "          [0.0053],\n",
       "          [0.0112],\n",
       "          [0.0092],\n",
       "          [0.0085],\n",
       "          [0.0057],\n",
       "          [0.0039],\n",
       "          [0.0101],\n",
       "          [0.0050],\n",
       "          [0.0122],\n",
       "          [0.0049],\n",
       "          [0.0050],\n",
       "          [0.0112],\n",
       "          [0.0031],\n",
       "          [0.0154],\n",
       "          [0.0084],\n",
       "          [0.0162]],\n",
       " \n",
       "         [[0.0151],\n",
       "          [0.0170],\n",
       "          [0.0112],\n",
       "          [0.0021],\n",
       "          [0.0104],\n",
       "          [0.0053],\n",
       "          [0.0053],\n",
       "          [0.0068],\n",
       "          [0.0217],\n",
       "          [0.0246],\n",
       "          [0.0127],\n",
       "          [0.0051],\n",
       "          [0.0266],\n",
       "          [0.0033],\n",
       "          [0.0295],\n",
       "          [0.0127],\n",
       "          [0.0222],\n",
       "          [0.0077],\n",
       "          [0.0036],\n",
       "          [0.0074]],\n",
       " \n",
       "         [[0.0051],\n",
       "          [0.0037],\n",
       "          [0.0179],\n",
       "          [0.0139],\n",
       "          [0.0057],\n",
       "          [0.0082],\n",
       "          [0.0030],\n",
       "          [0.0193],\n",
       "          [0.0161],\n",
       "          [0.0130],\n",
       "          [0.0080],\n",
       "          [0.0149],\n",
       "          [0.0047],\n",
       "          [0.0031],\n",
       "          [0.0302],\n",
       "          [0.0242],\n",
       "          [0.0174],\n",
       "          [0.0111],\n",
       "          [0.0108],\n",
       "          [0.0060]],\n",
       " \n",
       "         [[0.0199],\n",
       "          [0.0082],\n",
       "          [0.0219],\n",
       "          [0.0201],\n",
       "          [0.0175],\n",
       "          [0.0073],\n",
       "          [0.0027],\n",
       "          [0.0132],\n",
       "          [0.0134],\n",
       "          [0.0315],\n",
       "          [0.0037],\n",
       "          [0.0040],\n",
       "          [0.0059],\n",
       "          [0.0080],\n",
       "          [0.0029],\n",
       "          [0.0084],\n",
       "          [0.0063],\n",
       "          [0.0075],\n",
       "          [0.0136],\n",
       "          [0.0299]],\n",
       " \n",
       "         [[0.0679],\n",
       "          [0.0406],\n",
       "          [0.0939],\n",
       "          [0.0046],\n",
       "          [0.0038],\n",
       "          [0.0093],\n",
       "          [0.0151],\n",
       "          [0.0083],\n",
       "          [0.0116],\n",
       "          [0.0138],\n",
       "          [0.0189],\n",
       "          [0.0069],\n",
       "          [0.0069],\n",
       "          [0.0097],\n",
       "          [0.0305],\n",
       "          [0.0098],\n",
       "          [0.0173],\n",
       "          [0.0143],\n",
       "          [0.0146],\n",
       "          [0.0118]],\n",
       " \n",
       "         [[0.0261],\n",
       "          [0.0283],\n",
       "          [0.0232],\n",
       "          [0.0072],\n",
       "          [0.0195],\n",
       "          [0.0209],\n",
       "          [0.0398],\n",
       "          [0.0647],\n",
       "          [0.0040],\n",
       "          [0.0256],\n",
       "          [0.0085],\n",
       "          [0.0091],\n",
       "          [0.0286],\n",
       "          [0.0378],\n",
       "          [0.0580],\n",
       "          [0.0312],\n",
       "          [0.0083],\n",
       "          [0.0088],\n",
       "          [0.0225],\n",
       "          [0.0063]],\n",
       " \n",
       "         [[0.0115],\n",
       "          [0.0130],\n",
       "          [0.0132],\n",
       "          [0.0223],\n",
       "          [0.0166],\n",
       "          [0.0257],\n",
       "          [0.0126],\n",
       "          [0.0073],\n",
       "          [0.0309],\n",
       "          [0.0047],\n",
       "          [0.0075],\n",
       "          [0.0168],\n",
       "          [0.0032],\n",
       "          [0.0120],\n",
       "          [0.0085],\n",
       "          [0.0053],\n",
       "          [0.0046],\n",
       "          [0.0166],\n",
       "          [0.0138],\n",
       "          [0.0078]],\n",
       " \n",
       "         [[0.0156],\n",
       "          [0.0065],\n",
       "          [0.0056],\n",
       "          [0.0121],\n",
       "          [0.0195],\n",
       "          [0.0141],\n",
       "          [0.0107],\n",
       "          [0.0588],\n",
       "          [0.0267],\n",
       "          [0.0089],\n",
       "          [0.0209],\n",
       "          [0.0124],\n",
       "          [0.0136],\n",
       "          [0.0198],\n",
       "          [0.0142],\n",
       "          [0.0204],\n",
       "          [0.0127],\n",
       "          [0.0403],\n",
       "          [0.0464],\n",
       "          [0.0099]],\n",
       " \n",
       "         [[0.0300],\n",
       "          [0.0135],\n",
       "          [0.0121],\n",
       "          [0.0071],\n",
       "          [0.0227],\n",
       "          [0.0054],\n",
       "          [0.0006],\n",
       "          [0.0031],\n",
       "          [0.0053],\n",
       "          [0.0078],\n",
       "          [0.0070],\n",
       "          [0.0099],\n",
       "          [0.0208],\n",
       "          [0.0298],\n",
       "          [0.0006],\n",
       "          [0.0244],\n",
       "          [0.0030],\n",
       "          [0.0138],\n",
       "          [0.0129],\n",
       "          [0.0521]],\n",
       " \n",
       "         [[0.0125],\n",
       "          [0.0060],\n",
       "          [0.0025],\n",
       "          [0.0220],\n",
       "          [0.0191],\n",
       "          [0.0109],\n",
       "          [0.0034],\n",
       "          [0.0024],\n",
       "          [0.0146],\n",
       "          [0.0101],\n",
       "          [0.0266],\n",
       "          [0.0311],\n",
       "          [0.0085],\n",
       "          [0.0054],\n",
       "          [0.0038],\n",
       "          [0.0098],\n",
       "          [0.0063],\n",
       "          [0.0026],\n",
       "          [0.0073],\n",
       "          [0.0253]],\n",
       " \n",
       "         [[0.0223],\n",
       "          [0.0049],\n",
       "          [0.0286],\n",
       "          [0.0166],\n",
       "          [0.0078],\n",
       "          [0.0021],\n",
       "          [0.0236],\n",
       "          [0.0050],\n",
       "          [0.0141],\n",
       "          [0.0462],\n",
       "          [0.0055],\n",
       "          [0.0035],\n",
       "          [0.0059],\n",
       "          [0.0039],\n",
       "          [0.0027],\n",
       "          [0.0054],\n",
       "          [0.0155],\n",
       "          [0.0061],\n",
       "          [0.0139],\n",
       "          [0.0086]],\n",
       " \n",
       "         [[0.0021],\n",
       "          [0.0106],\n",
       "          [0.0113],\n",
       "          [0.0067],\n",
       "          [0.0265],\n",
       "          [0.0191],\n",
       "          [0.0132],\n",
       "          [0.0099],\n",
       "          [0.0107],\n",
       "          [0.0142],\n",
       "          [0.0402],\n",
       "          [0.0046],\n",
       "          [0.0359],\n",
       "          [0.0041],\n",
       "          [0.0061],\n",
       "          [0.0129],\n",
       "          [0.0065],\n",
       "          [0.0028],\n",
       "          [0.0023],\n",
       "          [0.0042]],\n",
       " \n",
       "         [[0.0061],\n",
       "          [0.0196],\n",
       "          [0.0191],\n",
       "          [0.0186],\n",
       "          [0.0090],\n",
       "          [0.0041],\n",
       "          [0.0041],\n",
       "          [0.0027],\n",
       "          [0.0148],\n",
       "          [0.0081],\n",
       "          [0.0069],\n",
       "          [0.0077],\n",
       "          [0.0204],\n",
       "          [0.0148],\n",
       "          [0.0062],\n",
       "          [0.0268],\n",
       "          [0.0147],\n",
       "          [0.0035],\n",
       "          [0.0047],\n",
       "          [0.0161]]], grad_fn=<CatBackward>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sampler(images, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
