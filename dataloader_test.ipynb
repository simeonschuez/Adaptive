{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "\n",
    "from data_utils import get_karpathy_split, refcoco_splits\n",
    "from data_loader import get_caption_loader, COCOCaptionDataset, get_reg_loader\n",
    "\n",
    "from build_vocab import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size=224\n",
    "image_dir='/home/simeon/Dokumente/Code/Data/COCO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coco_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_df = get_karpathy_split(splits_path='/home/simeon/Dokumente/Code/Data/COCO/splits/karpathy/caption_datasets/', caps_path='/home/simeon/Dokumente/Code/Data/COCO/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((crop_size, crop_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_caption_loader(\n",
    "        decoding_level='word', \n",
    "        split=['train'],\n",
    "        data_df=caps_df, \n",
    "        image_dir=image_dir, \n",
    "        vocab=vocab,\n",
    "        transform=transform, \n",
    "        batch_size=20, \n",
    "        shuffle=False,\n",
    "        num_workers=2, \n",
    "        drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, (images, captions, lengths, _, _) in enumerate(loader):    \n",
    "    if i > 2:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> the top of a kitchen cabinet covered with brass pots and pans <end> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [i.item() for i in captions[2]]\n",
    "' '.join([vocab.idx2word[i] for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/refcoco_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = refcoco_splits('/home/simeon/Dokumente/Code/Data/RefCOCO/refcoco/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_reg_loader(\n",
    "        decoding_level='word', \n",
    "        split=['train'],\n",
    "        data_df=ref_df, \n",
    "        image_dir=image_dir, \n",
    "        vocab=vocab,\n",
    "        transform=transform, \n",
    "        batch_size=20, \n",
    "        shuffle=False,\n",
    "        num_workers=2, \n",
    "        drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, (images, captions, positions, lengths, ann_ids, filenames) in enumerate(loader):    \n",
    "    if i > 2:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> leftmost animal edge of pic <end> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [i.item() for i in captions[2]]\n",
    "' '.join([vocab.idx2word[i] for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
